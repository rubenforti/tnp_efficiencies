
###############################################################################
#######  Logbook for TnP-efficiencies measurement  ############################
###############################################################################


14/03/2023
----------
Pulizia degli scripts esistenti e costruzione delle funzioni di import degli
istogrammi.

Pdf di fit dei dati costruita con RooHistPdf(mc_distribution) (x) smearing gaussiano;
combinazione di parametri che ha restituito un fit "accettabile":
    - interpolation_order=3
    - axis_bins=1000
    - buffer_fraction=0.1

Fit results:
    - Smearing: mu=-0.218+-0.056, sigma=0.97+-0.12
    - Chi2 pearson: measured=118.7, expected=78  ->  3.26 sigma



15/03/2023
----------
Funzione generale di import: dati i due file con gli istogrammi, fa il profile
lungo l'asse x e ritorna le seguenti q.tà:
    - Histos_data: tupla (fail, pass) di RooDataHist
    - Histos_mc:   tupla (fail, pass) di RooDataHist
    - nevts: tupla 2d formata da  ((ev_DATA_-, ev_DATA_+),
                                   (ev_MC_-  , ev_MC_+  ))
    - x: asse della massa invariante TP

Fit con pdf di smearing più bkg esponenziale, fatta sia per pass che per fail:
    - Pass:
        - Nsig_fit = 4836 +- 77 (4933 eventi nel dataset)
        - Chi2 pearson = 98.3  -> 1.9 sigma (DAJE)
    - Fail:
        - Nsig_fit = 442 +- 24 (469 eventi nel dataset)
        - Chi2 pearson non affidabile!

Nota: controllare le opzioni dei fit, per ora si è fatto tutto in MIGRAD, ma un
occhio ad HESSE non sarebbe male e tenere sotto controllo le opzioni del fit (
es. l'integrazione sul bin) è da fare.


16/03/2023
----------
Rimodulata la struttura dei file: adesso "fit_distrib" contiene la funzione che
effettua un fit (comprendente smearing e bkg) su una distribuzione; il modulo
"independent_fit" invece fa i fit sulle due distribuzioni e calcola l'efficienza.

Da fit con impostazioni uguali a ieri si ottiene: eff = 0.918 +- 0.016

Resta da capire se e come implementare delle opzioni dei fit (vedi sopra)

Una cosa MOLTO COMODA per la chiarezza del codice sarebbe riuscire a trovare il
modo di farsi ritornare una RooAddPdf (o anche RooAbsPdf in generale) da una
funzione di python. Perché per il momento va tutto bene (ritornare un RooFitResult
non dà problemi), ma per snellire il codice sarebbe comodo poter gestire in questo
modo anche le pdfs


22/03/2023
----------
Effettuato fit simultaneo sulle due distribuzioni, facendo entrare il parametro
efficienza tramite la conversione Nsig_fail = (1-eff)*Nsig_pass

Il risultato del fit sul bin [1,1] è consistente con quello trovato con fit
indipendenti: eff = 0.9113 +- 0.0055
Va capito se e come implementare una statistica di GOF per questi fit simultanei

Situazione del Pickle file: al momento per ogni bin viene salvata efficienza (val.
stimato ed errore) e risultati dei fit sui due dataset.
Implementata una classe che andrà a contenere le funzioni per gestire fondamentalmente
tutto: in particolare, va migliorato e utilizzato il metodo che restituisce i bin
nei quali il fit è stato problematico


31/03/2023
----------
Pickle file sistemato anche per i fit simultanei. La classe che gestisce il
file è stata corretta e sono state inserite le condizoni
        "migrad==0" && "covQual==3" && "edm < 10^-4"
per dire se un fit su un bin è riuscito.

WORKSPACE: inizializzato un oggetto RooWorkspace per tenere traccia di tutte le
PDF utilizzate su ogni bin. Da chiarire ancora esattamente come gestire l'oggetto
costruito perché le pdf non sono sovrascrivibili: questo può essere un limite
poiché l'idea era costruire delle pdf standard per ogni bin e poi salvarle e nel
caso modificarle. Forse la cosa migliore è salvare solo le pdf che soddisfano
le condizioni sopra e poi aggiungere via via le pdf corrette


02/04/2023
----------
Funziona l'operazione di aggiornare il ws con una PDF attraverso una funzione
python e successivamente estrarre tale PDF (senza sfruttare i "return" di python
che per le RooPdf non funzionano). Questo può essere utile in futuro, anche se
al momento costruire volta volta la pdf e fare il fit è più comodo, perché così
si salvano solo le pdf già utilizzate (che contengono quindi tutti i parametri
di fit)


03-04/04/2023
----------
Come "test di robustezza" per i fit (indep) su ogni bin mi era venuta l'idea di
far ripartire la minimizzazione dal punto già trovato. Questo può rivelarsi problematico
poiché per certi parametri la step-size della prima (nuova) iterazione può andare
oltre il limite della variabile stessa (v. Nbkg che spesso è ~ 0). Quindi o si
impone un controllo sulla step-size ogni volta (agendo su Minuit2) oppure non si
fa tutto sto lavoro, che poi non è che serva a molto.

Una cosa invece che può servire è salvare le pdf di INIT in ogni step. Il problema
qui è che queste si modificano col fit, quindi va implementato un sistema efficiente
per effettuare la copia  -->  non serve, infatti dato che viene salvato il "RooFitResult"
di ogni fit, questo contiene da sé i valori iniziali dei parametri (metodo "floatParsInit")


15-16/04/2023
-------------
Sistemata la sintassi della funzione che gestisce i diversi fit indipendenti e
aggiornata e ottimizzata la funzione di fit simultaneo (a 2 template). La cosa forse
più saggia adesso è fare una funzione comoda in un modulo a parte ("fit_manager")
che possa chiamare le funzioni di fit richieste (passando anche il METODO di stima)
come option.

Implementata la CMSShape per il fit indipendente: bisogna capire come impostare
i limiti dei 4 parametri, con le prove effettuate esce sempre un casino (fit status = 200 tipo)
perché il minimizzatore trova che Nbkg è al limite (e poi Hesse non trova una covmatrix
definita positiva...)
È solo un problema di inizializzazione/range dei parametri? Oppure si può riaprire
la possibilità di fare un test al bkg in questi casi?


17/04/2023
----------
Presi i valori iniziali della cmsshape dal programma di Marco, dove però questa
viene implementata SOLO NEI FAIL (per iso).
Effettuata prova sul bin (1,1): con i parametri iniziali del programma vecchio
il fit soddisfa le tre condizioni imposte finora ma ci sono TRE PARAMETRI AL LIMITE
(alpha_pass, beta_pass, beta_fail). Questo è un problema? Se sì bisogna implementare
un sistema che segnali quando queste cose avvengono (credo si possa fare attivando
minos e vedendo se questo dà un certo tipo di errore)

Questione cmsshape: la classe scritta custom eredita da RooAbsPdf, quindi ha già
tutti i metodi "fondamentali" di una pdf in roofit. Costruendo la pdf coi parametri
iniziali impostati, generando 10000 dati con tale distribuzione e effettuando un
fit tenendo libera la normalizzazione (con RooExtendPdf), si ottiene che il numero
stimato è 10000+-100, quindi perfettamente in accordo con una fluttuazione poissoniana
del numero di eventi. Se ne deduce che la normalizzazione non è il problema, cioè
questa viene fatta correttamente ogni volta all'interno della minimizzazione


20-21/04/2023
-------------
Quanto detto sopra è vero con l'algoritmo MINUIT. Se si imposta invece MINUIT2 le
cose si fanno più complicate e bisogna gestire accuratamente gli integrali numerici.
Se viene impostato il metodo dei trapezi, si ha una convergenza in un tempo ragionevole
richiedendo SOLO 12/15 STEPS, e inoltre il minimo che viene trovato non è quello
globale, poiché la normalizzazione stimata è totalmente diversa da quella attesa
e l'edm è ordine 50.
Se si imposta il metodo "bin center" si può aumentare il numero dei bin (e quindi
dei calcoli) fino a ordine 1000, ma il minimo trovato soffre delle stesse patologie
di quello descritto sopra.

In generale, sia per il metodo "bincenter" sia per quello dei trapezi, il numero
di steps non corrisponde al numero totale di punti in cui è calcolata la funzione
Per i trapezi infatti il numero di punti è ~2^(Nsteps), cosa che spiega perché
oltre 10-12 steps i calcoli non finiscono mai

TROVATA LA FORMULA PER L'INTEGRALE ANALITICO, grazie a WolframAlpha. Viene implementata
nella classe col metodo "analyticalIntegral", controllato da "getAnalyticalIntegral".
I template di questi due metodi sono stati presi dal codice sorgente della Breit-Wigner.
Minuit dovrebbe andare in automatico a cercare questi due metodi a ogni ciclo
per
normalizzare la pdf, che di per sé (come esce da "evaluate") non è normalizzata.


23-24/04/2023
-------------
CMSShape fatta girare sul bin (1,1) del dataset iso con Minuit2. Con la configurazione
precedente si verificava un problema che riguardava dei "bin in eccesso" che venivano
creati automaticamente. Probabilmente era una questione legata alla creazione del
buffer per la FFT (vedi "prepareFFTBinning"), per la quale Minuit2 si lamentava,
al contrario di Minuit. Il problema èstato risolto cambiando strategia al buffer,
da "Extend" a "Mirror", che mi sembra la più corretta --> in generale DA RIVEDERE
COSA SIGNIFICANO, non mi è chiarissimo  [#!!!!!#]

In questo modo il fit gira, ma si ottengono valori di EDM praticamente sempre
maggiori di 1 (di sicuro mai ordine 10^-5). Lo status del minimizer è quindi
sempre 3, mentre la covQual si riesce a far tornare =3.

Le cose cambiano però se si fa un "pre-fit" con Minuit (con anche impostazioni
blande e senza porre controlli) e solo successivamente si gira con Minuit2.
Potrebbe essere un procedimento corretto? Alla fine è un trucco per indirizzare
convenientemente Minuit2 verso il minimo, che altrimenti sembra non si riesca
a trovare.
Da notare comunque che le NLL ottenute con il pre-fit e senza sono molto vicine...
potrebbe quindi essere più un "vizio di forma" di Minuit2 che altro...  -->  No, 
peggio, vedi sotto


26/04/2023
----------
Prove di fit con MINUIT2 sui background del bin (1,1)

Impostazioni di partenza:
    range: default
    bins_fft = 2000
    buffer_fraction = 0.5 (strategy 2)
    normRange: no
    MaxCalls: 10000
    MaxIterations: 10000
    tolerance=2e-2
    min_strategy = 2
    SMEARING:   Mean: 0,-2,2    Sigma: 2,0.1,5
    BKG: no
----------> "top-level p.d.f evaluates to zero"
            3, 3, 1e-9

* MaxCalls -> 100000
----------> "top-level p.d.f evaluates to NaN", "p.d.f value is Not-a-Number",
            "p.d.f normalization integral is zero or negative"
            0, 3, 1e-4

* buffer_fraction = 0.1 (strategy 2)
----------> "top-level p.d.f evaluates to zero",
            3, 3, 1e-8


Visti questi problemi, si fanno delle prove con prova_cmsshape.py (tenendo fisso il
dataset generato). La cosa strana che succede è che a volte, ripetendo il fit con gli stessi
parametri, il valore di edm finale cambi in modo importante (1e-5 -> ~0.1).
Questo succede quando è chiamato un valore custom di TOLERANCE. Se si commenta
quel comando dovrebbe andare tutto bene

Tutto questo però SOLO SE i parametri iniziali coincidono con i parametri con cui
i dati sono stati generati!!!!!! Se si sposta anche di poco il valore di un parametro
iniziale (es. beta: 5.0->5.5) l'edm non scende più sotto ~0.1 e anzi gran parte delle
volte ha valori ordine 10/100


26/04-05/05/2023
----------------
Problemi con Minuit2 riassunti nel report da inviare a Josh. 
Si decide quindi di lavorare con ROOT 6.24/08 sulla macchina cmsanalysis (che ha CentOs7). La versione
scelta è l'ultima possibile per la quale Centos7 è un OS indicato. Purtroppo le varie "pythonizations"
sono disponibili solo dalla versione 6.26, quindi la sintassi è stata adattata.

Reso utilizzabile il modulo make_fits, che diventerà il "main" della repository.
La funzione per i fit indipendenti è stata rimodulata in modo che i parametri e le impostazioni siano
diversi per i due fit.


08-10/05/2023
-------------
Effettuata routine di fit indipendenti tenendo come parametri iniziali quelli presenti sul 
software esistente:
  - NBINS = 2000
  - buffer fractions = 0.5
  - PDF SIGNAL: mc con interpolazione 3, convoluta con gaussiana di smearing
  - SMEARING: gaussiana con mu(0, -5, 5), sigma(0.5, 0.1, 5)
  - FFT: interpolazione di default, quindi ordine 2
  - PDF BKG: exponential con tau(0, -5, 5)
  - NORMALIZZAZIONI: Nsig(0.9*ev, 0.5, 1.5*ev), Nbkg(0.1*ev, 0.5, 1.5*ev)
  - QUALITY CHECKS: status=(0,1), covQual=3, |chi2_meas-chi2_expected|<10*sigma_chi2
  - REFIT: se i check falliscono e Nbkg/Nsig<0.005, si fissa tau=1, Nbkg=0 e si riesegue il fit

Con queste impostazione tutti i fit riescono all'interno della routine. Fa eccezione in realtà il bin 
6,7 che ha l'unico difetto di avere un chi2 nei pass oltre le 10 sigma: visto che gli altri parametri 
di status sono sotto controllo e dato che IL CHECK SUL CHI2 NON VUOLE AVERE VALORE STATISTICO (come 
raccontato da Marco, è semplicemente un modo di scartare i casi in cui il minimizzatore trova un minimo
ad occhio di molto non aderente ai dati). Si procede quindi in questi casi ad aumentare "ad libitum" la 
soglia, in questo caso 12 sigma bastano.

NOTA: per errore inizialmente si era impostato sigma(0.5, **0.2**, 5). Questo aveva un effetto particolare 
su un bin, nel quale la stima di NBKG_fail risultava ~40 invece che ~11 come atteso --> si otteneva che la 
efficienza stimata distava 1.5 sigma da quella attesa. In nessuno dei due casi il parametro risultava al 
limite dopo la minimizzazione. Di fatto quindi alcune di queste misure sono sensibili a cambi nel range e 
nello step-size iniziale di (alcuni) parametri  [#!!!!!#]

Nella cartella "results/benchmark_iso" è stato salvato:
  - workspace con PDF e results objects
  - i plots dei singoli fit (in apposita cartella)
  - plot 2D di efficienza ed errore relativo
  - plot di confronto con risultati esistenti 


16-18/05/2023
-------------
Finito di sistemare il codice per i fit simultaneo; i parametri importati sono gli stessi di sopra, perché 
come primo test vogliamo verificare che si ottengano gli stessi risultati di sopra (il dataset infatti è 
lo stesso, non ha senso pensare che si riduca l'incertezza!).
La routine è completata in 6 runs:
  - Run 1: default settings  ->  11 problematic bins
  - Run 2: NBINS->5000       ->  6 prob. bins
  - Run 3: NBINS->10000      ->  4 prob. bins
  - Run 4: sigma(*1*, *0.4*, 5)  ->  2 prob. bins 
  - Run 5: check_chi2->15*sigma_chi2  ->  1 prob. bins (risolve sempre il bin 6,7)
  - Run 6: buffer->0.1, sigma(1, *0.05*, 5), NBINS->1000  ->  OK 

Il confronto coi risultati precedenti è buono e non si notano criticità. Tutto salvato analogamente a 
sopra nella cartella "results/benchmark_iso_sim"

Da queste analisi di confronto emergono delle possibilità di miglioramento della procedura di fit:
  - Strategia iniziale per la definizione dei parametri 
  - L'interpolazione va bene così?
  - La condizione per il refit, invece di un arbitrario S/B<0.005 potrebbe essere basata su quante sigma
    dista Nsig da Ntot. In un certo senso potrebbe essere simile a un LLR test? In ogni caso il LLR test
    sarebbe già pronto
  - Andrebbe posto un controllo sui parametri, per non salvare minimizzazioni che includono parametri al 
    limite. In questo caso potrebbe anche valere la pena essere conservativi.
  - Per quanto riguarda l'EDM invece non ha molto senso stare a richiedere un ordine 10^-5. ATTENZIONE 
    comunque che il valore restituito da res.edm() è il valore calcolato da HESSE, non da MIGRAD. Quale
    dei due conviene guardare, in ogni caso? 



24-26/05/2023
-------------
INIZIO DELL'ANALISI SUI BACKGROUNDS. Sempre considerando lo step "iso", si prendono gli istogrammi 3D di
ogni processo di background desiderato e si fa la proiezione nei bin selezionati. Ogni istogramma (quando
ancora è un TH1) viene moltiplicato per un fattore che è pari a Lumi_data/Lumi_bkg.

Dettagli sullo scaling: quando si chiama il metodo scale() viene attivata in automatico l'opzione SumW2 per
gli errori dell'istogramma. Ora, finché su quell'istogramma non ci si fa nulla va tutto bene, e infatti 
viene successivamente trasformato in un RooDataHist (che resterà sempre tale e quale).
VA VERIFICATO CHE GLI ERRORI DEL ROODATAHIST SIANO EFFETTIVAMENTE QUELLI CHE CI SI ASPETTA (ovvero 
sqrt(n)*scale)

Dettagli sui datasets a disposizione:
  - "ZZ" si riferisce solamente a ZZ->2l+2nu, con xs=0.60 pb. Non abbiamo a disposizione il dataset
    ZZ->2l+2q, che sarebbe più interessante perché ha un fattore 8.5 in sezione d'urto. La strategia attuale
    è di assumere che siano processi simili e che quindi ogni valutazione sul primo set si possa estendere 
    al secondo
  - "Ztautau" contiene solo una decina di eventi IN TOTALE. C'è chiaramente un problema di fondo, che dovrà
    risolvere qualcuno (sperem)


29/05-01/06/2023
----------------
Eventi di bkg "ZZ": la loro distribuzione in massa (per macro bin di pt e eta) è piccata a 90 GeV, come in 
parte atteso. La cosa da fare ora è confrontare la forma di questa distrib. con quella del MC di segnale
(Z->mumu), e decidere se etichettare questo processo come segnale

I passaggi successivi sono questi:
  - stabilire in modo preciso quanto un processo di bkg è rilevante.
  - fare un fit alle distribuzioni dei bkg sommati, in macro-bin di pt,eta se necessario
  - effettuare una nuova routine di fit con questo modello
  - confrontare i risultati con ipotesi esponenziale

ATTENZIONE: la funzione "get_roohist" è stata modificata in modo tale da accettare più bin di pt e/o eta,
al fine di fare un'analisi su macro-bin. I nomi dei dataset dipendono dalla forma con cui è passato l'indice
del bin, quindi va fatta attenzione quando ad es. si vuole importare un dataset di bkg da un workspace







~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

TO-DO LIST
----------
- Far girare fit simultanei su iso e confrontare coi risultati "indep"

- BACKGROUND: prendere i vari root files contenenti i diversi bkg e cercare di spiegare 
  un andamento esponenziale -> GOF test?

- Estendere l'analisi ad altri step -> se il lavoro sui bkg si dimostra promettente,
  rivogere particolare attenzione agli step "standalone" e "tracking"



DUBBI APERTI
------------
- Come si imposta la step-size in Minuit2? Non sembra esserci nessun metodo a tal fine né in RooMinimizer ne in ROOT.Fit.Fitter 



SYNTAX IMPROVEMENTS
-------------------
- Fare un main vero e proprio con rispettivo parser
- Cambiare la segnatura di ogni bin: (idx_pt|idx_eta)->[pt_low,pt_high]_[eta_low_eta_high]


IDEE PER MIGLIORAMENTI
----------------------
- LLR test sul parametro Nbkg (con H0: Nbkg=0): implementare una funzione opzionale
  che, in caso il test sia passato (con alpha=0.05), effettua un nuovo fit senza
  l'ipotesi di bkg

- Gestione degli istogrammi poco popolati: secondo un'idea di Marco si potrebbe utilizzare
  la distribuzione dei MC pass al posto della MC fail (?)

- Per i bin (pt,eta) difficoltosi: si può dividere il dataset in due, fare fit
  separati e vedere se la distribuzione della DIFFERENZA dei PULL è centrata in zero