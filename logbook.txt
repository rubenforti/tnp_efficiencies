
###############################################################################
#######  Logbook for TnP-efficiencies measurement  ############################
###############################################################################


14/03/2023
----------
Pulizia degli scripts esistenti e costruzione delle funzioni di import degli
istogrammi.

Pdf di fit dei dati costruita con RooHistPdf(mc_distribution) (x) smearing gaussiano;
combinazione di parametri che ha restituito un fit "accettabile":
    - interpolation_order=3
    - axis_bins=1000
    - buffer_fraction=0.1

Fit results:
    - Smearing: mu=-0.218+-0.056, sigma=0.97+-0.12
    - Chi2 pearson: measured=118.7, expected=78  ->  3.26 sigma



15/03/2023
----------
Funzione generale di import: dati i due file con gli istogrammi, fa il profile
lungo l'asse x e ritorna le seguenti q.tà:
    - Histos_data: tupla (fail, pass) di RooDataHist
    - Histos_mc:   tupla (fail, pass) di RooDataHist
    - nevts: tupla 2d formata da  ((ev_DATA_-, ev_DATA_+),
                                   (ev_MC_-  , ev_MC_+  ))
    - x: asse della massa invariante TP

Fit con pdf di smearing più bkg esponenziale, fatta sia per pass che per fail:
    - Pass:
        - Nsig_fit = 4836 +- 77 (4933 eventi nel dataset)
        - Chi2 pearson = 98.3  -> 1.9 sigma (DAJE)
    - Fail:
        - Nsig_fit = 442 +- 24 (469 eventi nel dataset)
        - Chi2 pearson non affidabile!

Nota: controllare le opzioni dei fit, per ora si è fatto tutto in MIGRAD, ma un
occhio ad HESSE non sarebbe male e tenere sotto controllo le opzioni del fit (
es. l'integrazione sul bin) è da fare.


16/03/2023
----------
Rimodulata la struttura dei file: adesso "fit_distrib" contiene la funzione che
effettua un fit (comprendente smearing e bkg) su una distribuzione; il modulo
"independent_fit" invece fa i fit sulle due distribuzioni e calcola l'efficienza.

Da fit con impostazioni uguali a ieri si ottiene: eff = 0.918 +- 0.016

Resta da capire se e come implementare delle opzioni dei fit (vedi sopra)

Una cosa MOLTO COMODA per la chiarezza del codice sarebbe riuscire a trovare il
modo di farsi ritornare una RooAddPdf (o anche RooAbsPdf in generale) da una
funzione di python. Perché per il momento va tutto bene (ritornare un RooFitResult
non dà problemi), ma per snellire il codice sarebbe comodo poter gestire in questo
modo anche le pdfs


22/03/2023
----------
Effettuato fit simultaneo sulle due distribuzioni, facendo entrare il parametro
efficienza tramite la conversione Nsig_fail = (1-eff)*Nsig_pass

Il risultato del fit sul bin [1,1] è consistente con quello trovato con fit
indipendenti: eff = 0.9113 +- 0.0055
Va capito se e come implementare una statistica di GOF per questi fit simultanei

Situazione del Pickle file: al momento per ogni bin viene salvata efficienza (val.
stimato ed errore) e risultati dei fit sui due dataset.
Implementata una classe che andrà a contenere le funzioni per gestire fondamentalmente
tutto: in particolare, va migliorato e utilizzato il metodo che restituisce i bin
nei quali il fit è stato problematico


31/03/2023
----------
Pickle file sistemato anche per i fit simultanei. La classe che gestisce il
file è stata corretta e sono state inserite le condizoni
        "migrad==0" && "covQual==3" && "edm < 10^-4"
per dire se un fit su un bin è riuscito.

WORKSPACE: inizializzato un oggetto RooWorkspace per tenere traccia di tutte le
PDF utilizzate su ogni bin. Da chiarire ancora esattamente come gestire l'oggetto
costruito perché le pdf non sono sovrascrivibili: questo può essere un limite
poiché l'idea era costruire delle pdf standard per ogni bin e poi salvarle e nel
caso modificarle. Forse la cosa migliore è salvare solo le pdf che soddisfano
le condizioni sopra e poi aggiungere via via le pdf corrette


02/04/2023
----------
Funziona l'operazione di aggiornare il ws con una PDF attraverso una funzione
python e successivamente estrarre tale PDF (senza sfruttare i "return" di python
che per le RooPdf non funzionano). Questo può essere utile in futuro, anche se
al momento costruire volta volta la pdf e fare il fit è più comodo, perché così
si salvano solo le pdf già utilizzate (che contengono quindi tutti i parametri
di fit)


03-04/04/2023
----------
Come "test di robustezza" per i fit (indep) su ogni bin mi era venuta l'idea di
far ripartire la minimizzazione dal punto già trovato. Questo può rivelarsi problematico
poiché per certi parametri la step-size della prima (nuova) iterazione può andare
oltre il limite della variabile stessa (v. Nbkg che spesso è ~ 0). Quindi o si
impone un controllo sulla step-size ogni volta (agendo su Minuit2) oppure non si
fa tutto sto lavoro, che poi non è che serva a molto.

Una cosa invece che può servire è salvare le pdf di INIT in ogni step. Il problema
qui è che queste si modificano col fit, quindi va implementato un sistema efficiente
per effettuare la copia  -->  non serve, infatti dato che viene salvato il "RooFitResult"
di ogni fit, questo contiene da sé i valori iniziali dei parametri (metodo "floatParsInit")


15-16/04/2023
-------------
Sistemata la sintassi della funzione che gestisce i diversi fit indipendenti e
aggiornata e ottimizzata la funzione di fit simultaneo (a 2 template). La cosa forse
più saggia adesso è fare una funzione comoda in un modulo a parte ("fit_manager")
che possa chiamare le funzioni di fit richieste (passando anche il METODO di stima)
come option.

Implementata la CMSShape per il fit indipendente: bisogna capire come impostare
i limiti dei 4 parametri, con le prove effettuate esce sempre un casino (fit status = 200 tipo)
perché il minimizzatore trova che Nbkg è al limite (e poi Hesse non trova una covmatrix
definita positiva...)
È solo un problema di inizializzazione/range dei parametri? Oppure si può riaprire
la possibilità di fare un test al bkg in questi casi?


17/04/2023
----------
Presi i valori iniziali della cmsshape dal programma di Marco, dove però questa
viene implementata SOLO NEI FAIL (per iso).
Effettuata prova sul bin (1,1): con i parametri iniziali del programma vecchio
il fit soddisfa le tre condizioni imposte finora ma ci sono TRE PARAMETRI AL LIMITE
(alpha_pass, beta_pass, beta_fail). Questo è un problema? Se sì bisogna implementare
un sistema che segnali quando queste cose avvengono (credo si possa fare attivando
minos e vedendo se questo dà un certo tipo di errore)

Questione cmsshape: la classe scritta custom eredita da RooAbsPdf, quindi ha già
tutti i metodi "fondamentali" di una pdf in roofit. Costruendo la pdf coi parametri
iniziali impostati, generando 10000 dati con tale distribuzione e effettuando un
fit tenendo libera la normalizzazione (--> RooExtendedTerm, da moltiplicare alla
cmsshape) si ottiene che il numero stimato è 10000+-100, quindi perfettamente in
accordo con una fluttuazione poissoniana del numero di eventi. Se ne deduce che
la normalizzazione non è il problema, cioè questa viene fatta correttamente ogni
vlta all'interno della minimizzazione --> GIUSTO?








~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

TO-DO LIST
----------

- Implementare la CMSSHAPE come background

- Costruire un modulo che permetta di gestire in modo efficiente i diversi cicli
  di fit

- Aggiornare la classe results per i fit simultanei

- Trovare il modo di salvarsi le pdf iniziali nel workspace. Vedere se a tale
  scopo può essere utile il metodo "factory"

- Fit simultaneo tra pass e fail ANCHE sui mc: come PDF dei mc si usa una
  RooExtendPdf e si fa la trasformazione eff -> (sf)*(eff_mc)

- Iso with same charge dataset:
    - Studio generale: confrontare le distribuzioni dei dati rispetto al
      montecarlo in macro-bin di (pt,eta)
    - Studio particolare: per ogni bin valutare quanta parte del fondo visto
      nei dati è attribuibile ai diversi tipi di fondi: QCD (rappresentati dai
      DATI "samecharge"), drell-Yan non prompt ecc.


IDEE PER MIGLIORAMENTI
----------------------
  - LLR test sul parametro Nbkg (con H0: Nbkg=0): implementare una funzione opzionale
    che, in caso il test sia passato (con alpha=0.05), effettua un nuovo fit senza
    l'ipotesi di bkg
  - Per i bin (pt,eta) difficoltosi: si può dividere il dataset in due, fare fit
    separati e vedere se la distribuzione della DIFFERENZA dei PULL è centrata in zero
