
###############################################################################
#######  Logbook for TnP-efficiencies measurement  ############################
###############################################################################


14/03/2023
----------
Pulizia degli scripts esistenti e costruzione delle funzioni di import degli
istogrammi.

Pdf di fit dei dati costruita con RooHistPdf(mc_distribution) (x) smearing gaussiano;
combinazione di parametri che ha restituito un fit "accettabile":
    - interpolation_order=3
    - axis_bins=1000
    - buffer_fraction=0.1

Fit results:
    - Smearing: mu=-0.218+-0.056, sigma=0.97+-0.12
    - Chi2 pearson: measured=118.7, expected=78  ->  3.26 sigma



15/03/2023
----------
Funzione generale di import: dati i due file con gli istogrammi, fa il profile
lungo l'asse x e ritorna le seguenti q.t√†:
    - Histos_data: tupla (fail, pass) di RooDataHist
    - Histos_mc:   tupla (fail, pass) di RooDataHist
    - nevts: tupla 2d formata da  ((ev_DATA_-, ev_DATA_+),
                                   (ev_MC_-  , ev_MC_+  ))
    - x: asse della massa invariante TP

Fit con pdf di smearing pi√π bkg esponenziale, fatta sia per pass che per fail:
    - Pass:
        - Nsig_fit = 4836 +- 77 (4933 eventi nel dataset)
        - Chi2 pearson = 98.3  -> 1.9 sigma (DAJE)
    - Fail:
        - Nsig_fit = 442 +- 24 (469 eventi nel dataset)
        - Chi2 pearson non affidabile!

Nota: controllare le opzioni dei fit, per ora si √® fatto tutto in MIGRAD, ma un
occhio ad HESSE non sarebbe male e tenere sotto controllo le opzioni del fit (
es. l'integrazione sul bin) √® da fare.


16/03/2023
----------
Rimodulata la struttura dei file: adesso "fit_distrib" contiene la funzione che
effettua un fit (comprendente smearing e bkg) su una distribuzione; il modulo
"independent_fit" invece fa i fit sulle due distribuzioni e calcola l'efficienza.

Da fit con impostazioni uguali a ieri si ottiene: eff = 0.918 +- 0.016

Resta da capire se e come implementare delle opzioni dei fit (vedi sopra)

Una cosa MOLTO COMODA per la chiarezza del codice sarebbe riuscire a trovare il
modo di farsi ritornare una RooAddPdf (o anche RooAbsPdf in generale) da una
funzione di python. Perch√© per il momento va tutto bene (ritornare un RooFitResult
non d√† problemi), ma per snellire il codice sarebbe comodo poter gestire in questo
modo anche le pdfs


22/03/2023
----------
Effettuato fit simultaneo sulle due distribuzioni, facendo entrare il parametro
efficienza tramite la conversione Nsig_fail = (1-eff)*Nsig_pass

Il risultato del fit sul bin [1,1] √® consistente con quello trovato con fit
indipendenti: eff = 0.9113 +- 0.0055
Va capito se e come implementare una statistica di GOF per questi fit simultanei

Situazione del Pickle file: al momento per ogni bin viene salvata efficienza (val.
stimato ed errore) e risultati dei fit sui due dataset.
Implementata una classe che andr√† a contenere le funzioni per gestire fondamentalmente
tutto: in particolare, va migliorato e utilizzato il metodo che restituisce i bin
nei quali il fit √® stato problematico


31/03/2023
----------
Pickle file sistemato anche per i fit simultanei. La classe che gestisce il
file √® stata corretta e sono state inserite le condizoni
        "migrad==0" && "covQual==3" && "edm < 10^-4"
per dire se un fit su un bin √® riuscito.

WORKSPACE: inizializzato un oggetto RooWorkspace per tenere traccia di tutte le
PDF utilizzate su ogni bin. Da chiarire ancora esattamente come gestire l'oggetto
costruito perch√© le pdf non sono sovrascrivibili: questo pu√≤ essere un limite
poich√© l'idea era costruire delle pdf standard per ogni bin e poi salvarle e nel
caso modificarle. Forse la cosa migliore √® salvare solo le pdf che soddisfano
le condizioni sopra e poi aggiungere via via le pdf corrette


02/04/2023
----------
Funziona l'operazione di aggiornare il ws con una PDF attraverso una funzione
python e successivamente estrarre tale PDF (senza sfruttare i "return" di python
che per le RooPdf non funzionano). Questo pu√≤ essere utile in futuro, anche se
al momento costruire volta volta la pdf e fare il fit √® pi√π comodo, perch√© cos√¨
si salvano solo le pdf gi√† utilizzate (che contengono quindi tutti i parametri
di fit)


03-04/04/2023
----------
Come "test di robustezza" per i fit (indep) su ogni bin mi era venuta l'idea di
far ripartire la minimizzazione dal punto gi√† trovato. Questo pu√≤ rivelarsi problematico
poich√© per certi parametri la step-size della prima (nuova) iterazione pu√≤ andare
oltre il limite della variabile stessa (v. Nbkg che spesso √® ~ 0). Quindi o si
impone un controllo sulla step-size ogni volta (agendo su Minuit2) oppure non si
fa tutto sto lavoro, che poi non √® che serva a molto.

Una cosa invece che pu√≤ servire √® salvare le pdf di INIT in ogni step. Il problema
qui √® che queste si modificano col fit, quindi va implementato un sistema efficiente
per effettuare la copia  -->  non serve, infatti dato che viene salvato il "RooFitResult"
di ogni fit, questo contiene da s√© i valori iniziali dei parametri (metodo "floatParsInit")


15-16/04/2023
-------------
Sistemata la sintassi della funzione che gestisce i diversi fit indipendenti e
aggiornata e ottimizzata la funzione di fit simultaneo (a 2 template). La cosa forse
pi√π saggia adesso √® fare una funzione comoda in un modulo a parte ("fit_manager")
che possa chiamare le funzioni di fit richieste (passando anche il METODO di stima)
come option.

Implementata la CMSShape per il fit indipendente: bisogna capire come impostare
i limiti dei 4 parametri, con le prove effettuate esce sempre un casino (fit status = 200 tipo)
perch√© il minimizzatore trova che Nbkg √® al limite (e poi Hesse non trova una covmatrix
definita positiva...)
√à solo un problema di inizializzazione/range dei parametri? Oppure si pu√≤ riaprire
la possibilit√† di fare un test al bkg in questi casi?


17/04/2023
----------
Presi i valori iniziali della cmsshape dal programma di Marco, dove per√≤ questa
viene implementata SOLO NEI FAIL (per iso).
Effettuata prova sul bin (1,1): con i parametri iniziali del programma vecchio
il fit soddisfa le tre condizioni imposte finora ma ci sono TRE PARAMETRI AL LIMITE
(alpha_pass, beta_pass, beta_fail). Questo √® un problema? Se s√¨ bisogna implementare
un sistema che segnali quando queste cose avvengono (credo si possa fare attivando
minos e vedendo se questo d√† un certo tipo di errore)

Questione cmsshape: la classe scritta custom eredita da RooAbsPdf, quindi ha gi√†
tutti i metodi "fondamentali" di una pdf in roofit. Costruendo la pdf coi parametri
iniziali impostati, generando 10000 dati con tale distribuzione e effettuando un
fit tenendo libera la normalizzazione (con RooExtendPdf), si ottiene che il numero
stimato √® 10000+-100, quindi perfettamente in accordo con una fluttuazione poissoniana
del numero di eventi. Se ne deduce che la normalizzazione non √® il problema, cio√®
questa viene fatta correttamente ogni volta all'interno della minimizzazione


20-21/04/2023
-------------
Quanto detto sopra √® vero con l'algoritmo MINUIT. Se si imposta invece MINUIT2 le
cose si fanno pi√π complicate e bisogna gestire accuratamente gli integrali numerici.
Se viene impostato il metodo dei trapezi, si ha una convergenza in un tempo ragionevole
richiedendo SOLO 12/15 STEPS, e inoltre il minimo che viene trovato non √® quello
globale, poich√© la normalizzazione stimata √® totalmente diversa da quella attesa
e l'edm √® ordine 50.
Se si imposta il metodo "bin center" si pu√≤ aumentare il numero dei bin (e quindi
dei calcoli) fino a ordine 1000, ma il minimo trovato soffre delle stesse patologie
di quello descritto sopra.

In generale, sia per il metodo "bincenter" sia per quello dei trapezi, il numero
di steps non corrisponde al numero totale di punti in cui √®calcolata la funzione
Per i trapezi infatti il numero di punti √ ~2^(Nsteps), cosa che spiega perch√©
oltre 10-12 steps i calcoli non finiscono mai

TROVATA LA FORMULA PER L'INTEGRALE ANALITICO, grazie a WolframAlpha. Viene implementata
nella classe col metodo "analyticalIntegral", controllato da "getAnalyticalIntegral".
I template di questi due metodi sono stati presi dal codice sorgente della Breit-Wigner.
Minuit dovrebbe andare in automatico a cercare questi due metodi a ogni ciclo 
per
normalizzare la pdf, che di per s√ (come esce da "evaluate") non √®normalizzata.


23-24/04/2023
-------------
CMSShape fatta girare sul bin (1,1) del dataset iso con Minuit2. Con la configurazione 
precedente si verificava un problema che riguardava dei "bin in eccesso" che venivano 
creati automaticamente. Probabilmente era una questione legata alla creazione del 
buffer per la FFT (vedi "prepareFFTBinning"), per la quale Minuit2 si lamentava,
al contrario di Minuit. Il problema √®stato risoltocambiando strategia al buffer,
da "Extend" a "Mirror", che mi sembra la pi√ corretta (in generale DA RIVEDERE
COSA SIGNIFICANO, non mi √®chiarissimo)

In questo modo il fit gira, ma si ottengono valori di EDM praticamente sempre
maggiori di 1 (di sicuro mai ordine 10^-5). Lo status del minimizer √®quindi
sempre 3, mentre la covQual si riesce a far tornare =3.

Le cose cambiano per√≤se si fa un "pre-fit" con Minuit (con anche impostazioni
blande e senza porre controlli) e solo successivamente si gira con Minuit2.
Potrebbe essere un procedimento corretto? Alla fine √®un trucco per indirizzare
convenientemente Minuit2 verso il minimo, che altrimenti sembra non si riesca
a trovare.
Da notare comunque che le NLL ottenute con il pre-fit e senza sono molto vicine...
potrebbe quindi essere pi√πun "vizio di forma" di Minuit2 che altro... (???)














~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

TO-DO LIST
----------

- Implementare la CMSSHAPE come background

- Costruire un modulo che permetta di gestire in modo efficiente i diversi cicli
  di fit

- Aggiornare la classe results per i fit simultanei

- Trovare il modo di salvarsi le pdf iniziali nel workspace. Vedere se a tale
  scopo pu√≤ essere utile il metodo "factory"

- Fit simultaneo tra pass e fail ANCHE sui mc: come PDF dei mc si usa una
  RooExtendPdf e si fa la trasformazione eff -> (sf)*(eff_mc)

- Iso with same charge dataset:
    - Studio generale: confrontare le distribuzioni dei dati rispetto al
      montecarlo in macro-bin di (pt,eta)
    - Studio particolare: per ogni bin valutare quanta parte del fondo visto
      nei dati √® attribuibile ai diversi tipi di fondi: QCD (rappresentati dai
      DATI "samecharge"), drell-Yan non prompt ecc.


IDEE PER MIGLIORAMENTI
----------------------
  - LLR test sul parametro Nbkg (con H0: Nbkg=0): implementare una funzione opzionale
    che, in caso il test sia passato (con alpha=0.05), effettua un nuovo fit senza
    l'ipotesi di bkg
  - Per i bin (pt,eta) difficoltosi: si pu√≤ dividere il dataset in due, fare fit
    separati e vedere se la distribuzione della DIFFERENZA dei PULL √® centrata in zero
